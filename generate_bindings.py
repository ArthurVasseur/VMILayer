#!/usr/bin/env python3
import json
import os
import sys

type_mapping = {
    "i32": {"cpp": "cct::Int32", "rust": "i32", "sql": "INTEGER"},
    "i64": {"cpp": "cct::Int64", "rust": "i64", "sql": "BIGINT"},
    "str": {"cpp": "std::string", "rust": "String", "sql": "TEXT"}
}

def snake_to_camel(name: str) -> str:
    return "".join(word.capitalize() for word in name.split('_'))

def snake_to_field(name: str) -> str:
    parts = name.split('_')
    return parts[0].lower() + "".join(word.capitalize() for word in parts[1:])

def generate_rust_binding(table: dict) -> str:
    struct_name = snake_to_camel(table["name"])
    code = []
    # Struct definition
    code.append(f"#[derive(Debug, serde::Serialize)]")
    code.append(f"pub struct {struct_name} {{")
    for col in table["columns"]:
        rust_type = type_mapping[col["type"]]["rust"]
        field_name = col["name"]
        code.append(f"    pub {field_name}: {rust_type},")
    code.append("}\n")

    # Implementation block with serialize() and deserialize()
    code.append(f"impl {struct_name} {{")
    # Serialization
    code.append("    pub fn serialize(&self) -> Vec<u8> {")
    code.append("        let mut buffer = Vec::new();")
    for col in table["columns"]:
        col_type = col["type"]
        field_name = col["name"]
        code.append(f"        // Serialize field: {field_name}")
        if col_type in ["i32", "i64"]:
            code.append(f"        buffer.extend(&self.{field_name}.to_be_bytes());")
        elif col_type == "str":
            code.append(f"        let s_bytes = self.{field_name}.as_bytes();")
            code.append("        let s_len = s_bytes.len() as u32;")
            code.append("        buffer.extend(&s_len.to_be_bytes());")
            code.append("        buffer.extend(s_bytes);")
    code.append("        buffer")
    code.append("    }")
    code.append("")
    # Deserialization
    code.append("    pub fn deserialize(data: &[u8]) -> Result<Self, String> {")
    code.append("        let mut offset = 0;")
    field_values = []
    for col in table["columns"]:
        col_type = col["type"]
        field_name = col["name"]

        code.append(f"         // Deserialize field: {field_name}")
        if col_type in ["i32"] or col_type == "i64":
            code.append(f"         if offset + std::mem::size_of::<{col_type}>() > data.len() {{ return Err(\"Not enough data for field: {field_name}\".to_owned()); }}")
            code.append(f"         let slice = data[offset..offset + std::mem::size_of::<{col_type}>()].try_into();")
            code.append(f"         if slice.is_err() {{ return Err(format!(\"Failed to convert to {col_type} at line: {{}}\", line!())); }}")
            code.append(f"         let slice = slice.unwrap();")
            code.append(f"         let {field_name} = {col_type}::from_be_bytes(slice);")
            code.append(f"         offset += std::mem::size_of::<{col_type}>();")
        elif col_type == "str":
            code.append(f"         if offset + std::mem::size_of::<u32>() > data.len() {{ return Err(\"Not enough data for field: {field_name}\".to_owned()); }}")
            code.append(f"         let slice_result = data[offset..offset + std::mem::size_of::<u32>()].try_into();")
            code.append(f"         if slice_result.is_err() {{ return Err(format!(\"Failed to convert to u32 at line: {{}}\", line!())); }}")
            code.append(f"         let slice = slice_result.unwrap();")
            code.append(f"         let len = u32::from_be_bytes(slice);")
            code.append(f"         offset += std::mem::size_of::<u32>();")
            code.append(f"         if offset + len as usize > data.len() {{ return Err(\"Not enough data for field: {field_name}\".to_owned()); }}")
            code.append(f"         let str_slice = &data[offset..offset + len as usize];")
            code.append(f"         let s = String::from_utf8(str_slice.to_vec());")
            code.append(f"         if s.is_err() {{ return Err(format!(\"Failed to convert to String at line: {{}}\", line!())); }}")
            code.append(f"         let {field_name} = s.unwrap();")
            code.append(f"         offset += len as usize;")
        field_values.append(field_name)
    # Build the struct with all fields
    code.append(f"        Ok({struct_name} {{")
    for field in field_values:
        code.append(f"            {field},")
    code.append("        })")
    code.append("    }")
    code.append("}")
    return "\n".join(code)

def generate_rust_file(json_data: dict) -> str:
    header = (
        "// This file is generated by generate_bindings.py\n"
        "// Do not edit manually\n"
        "\n"
        "use std::convert::TryInto;\n\n"
    )
    bindings = []
    # Generate bindings for each table
    for table in json_data["tables"]:
        bindings.append(generate_rust_binding(table))
        bindings.append("\n")
    
    # Generate the Packet enum with dispatching on a u32 command id.
    bindings.append("#[derive(Debug)]")
    bindings.append("pub enum Packet {")
    for i, table in enumerate(json_data["tables"]):
        variant = snake_to_camel(table["name"])
        bindings.append(f"    {variant}({variant}),")
    bindings.append("}\n")
    
    bindings.append("impl Packet {")
    # Serialization: prepend a 4-byte command id (big-endian) then the serialized data.
    bindings.append("    pub fn serialize(&self) -> Vec<u8> {")
    bindings.append("        let mut buffer = Vec::new();")
    bindings.append("        match self {")
    for i, table in enumerate(json_data["tables"]):
        variant = snake_to_camel(table["name"])
        bindings.append(f"            Packet::{variant}(val) => {{")
        bindings.append(f"                buffer.extend(&({i}u32).to_be_bytes());")
        bindings.append("                buffer.extend(&val.serialize());")
        bindings.append("            },")
    bindings.append("        }")
    bindings.append("        buffer")
    bindings.append("    }")
    bindings.append("")
    # Deserialization: read the first 4 bytes as command id then deserialize accordingly.
    bindings.append("    pub fn deserialize(data: &[u8]) -> Option<Packet> {")
    bindings.append("        if data.len() < 4 {")
    bindings.append("            return None;")
    bindings.append("        }")
    bindings.append("        let command_id = u32::from_be_bytes(data[0..4].try_into().ok()?);")
    bindings.append("        let payload = &data[4..];")
    bindings.append("        match command_id {")
    for i, table in enumerate(json_data["tables"]):
        variant = snake_to_camel(table["name"])
        bindings.append(f"            {i} => {{")
        bindings.append(f"                match {variant}::deserialize(payload) {{")
        bindings.append(f"                  Ok(val) => Some(Packet::{variant}(val)),")
        bindings.append(f"                  Err(error_message) => {{println!(\"Failed to deserialize {variant}, {{}}: \", error_message); None}}")
        bindings.append("                }")
        bindings.append("            },")
    bindings.append("            v => {println!(\"Unknown enum value: {}\", v);None}")
    bindings.append("        }")
    bindings.append("    }")
    bindings.append("}\n")
    
    return header + "\n".join(bindings)

def generate_sql_schema(table: dict) -> str:
    lines = []
    table_name = table["name"]
    lines.append(f"CREATE TABLE {table_name} (")
    col_lines = []
    for col in table["columns"]:
        sql_type = type_mapping[col["type"]]["sql"]
        line = f"    {col['name']} {sql_type}"
        if col.get("primary_key", False):
            line += " PRIMARY KEY"
            if col.get("autoincrement", False):
                line += " AUTOINCREMENT"
        if col.get("not_null", False):
            line += " NOT NULL"
        col_lines.append(line)
    lines.append(",\n".join(col_lines))
    lines.append(");")
    return "\n".join(lines)

def generate_sql_file(json_data: dict) -> str:
    code = "pub const DATABASE_SCHEMA: &str = r###\""
    for table in json_data["tables"]:
        code += generate_sql_schema(table)
        code += "\n"
    code += "\"###;\n\n"
    return code

def generate_cpp_file(json_data: dict) -> str:
    header = (
        "/// This file is generated by generate_bindings.py\n"
        "/// Do not edit manually\n"
        "#pragma once\n"
        "#include <cstdint>\n"
        "#include <vector>\n"
        "#include <string>\n"
        "#include <cstring>\n"
        "#include <variant>\n"
        "#include <span>\n"
        "#include <Concerto/Core/ByteSwap.hpp>\n\n"
    )
    classes = []
    classes.append(f"enum class EventType {{")
    for i, value in enumerate(json_data["tables"]):
        classes.append(f"\t{snake_to_camel(value['name'])} = {i},")
    classes.append("};")
    classes.append("\n")
    for table in json_data["tables"]:
        classes.append(generate_cpp_binding(table))
        classes.append("\n")
    code = "inline std::variant<std::monostate, "
    for klass in json_data["tables"]:
        code += f"{snake_to_camel(klass['name'])}, "
    code = code[:-2] + "> Deserialize(const std::vector<cct::Byte>& data) {\n"
    code += "\tdecltype(Deserialize(data)) res;\n"
    code += "\tif (data.size() < sizeof(cct::UInt32)) return res;\n"
    code += "\tcct::UInt32 type;\n"
    code += "\tstd::memcpy(&type, data.data(), sizeof(cct::UInt32));\n"
    code += "\ttype = cct::ByteSwap(type);\n"
    code += "\tswitch (type) {\n"
    for i, table in enumerate(json_data["tables"]):
        code += f"\t\tcase {i}:\n"
        code += f"\t\t\tres = {snake_to_camel(table['name'])}::deserialize(std::span<const cct::Byte>(data.data() + sizeof(cct::UInt32), data.size() - sizeof(cct::UInt32)));\n"
        code += "\t\t\tbreak;\n"
    code += "\t\tdefault:\n"
    code += "\t\t\tbreak;\n"
    code += "\t}\n"
    code += "\treturn res;\n"
    code += "}\n\n"

    code += "template<typename T>\n"
    code += "inline std::vector<cct::Byte> Serialize(const T& obj) {\n"
    code += "\tstd::vector<cct::Byte> buffer(sizeof(cct::UInt32));\n"
    for table in json_data["tables"]:
        code += f"\tif constexpr (std::is_same_v<T, {snake_to_camel(table['name'])}>) {{\n"
        code += f"\t\tcct::UInt32 type = static_cast<cct::UInt32>(EventType::{snake_to_camel(table['name'])});\n"
        code += "\t\ttype = cct::ByteSwap(type);\n"
        code += "\t\tstd::memcpy(buffer.data(), &type, sizeof(cct::UInt32));\n"
        code += "\t\tauto serializedType = obj.serialize();\n"
        code += "\t\tbuffer.insert(buffer.end(), serializedType.begin(), serializedType.end());\n"
        code += "\t\treturn buffer;\n"
        code += "\t}\n"
    code += "\treturn buffer;\n"
    code += "}\n\n"
    return header + "\n".join(classes) + "\n" + code

def generate_cpp_binding(table: dict) -> str:
    class_name = snake_to_camel(table["name"])
    code = []
    code.append(f"class {class_name} {{")
    code.append("public:")
    for col in table["columns"]:
        cpp_type = type_mapping[col["type"]]["cpp"]
        field_name = snake_to_field(col["name"])
        code.append(f"\t{cpp_type} {field_name};")
    code.append("")
    code.append("\tstd::vector<cct::Byte> serialize() const {")
    code.append("\t\tsize_t total_size = 0;")
    for col in table["columns"]:
        field_name = snake_to_field(col["name"])
        if col["type"] == "str":
            code.append(f"\t\ttotal_size += sizeof(cct::UInt32) + {field_name}.size();")
        else:
            cpp_type = type_mapping[col["type"]]["cpp"]
            code.append(f"\t\ttotal_size += sizeof({cpp_type});")
    code.append("\t\tstd::vector<cct::Byte> buffer(total_size);")
    code.append("\t\tsize_t offset = 0;")
    for col in table["columns"]:
        cpp_type = type_mapping[col["type"]]["cpp"]
        field_name = snake_to_field(col["name"])
        if col["type"] == "str":
            code.append(f'\t\tcct::UInt32 len_{field_name} = static_cast<cct::UInt32>({field_name}.size());')
            code.append(f'\t\tlen_{field_name} = cct::ByteSwap(len_{field_name});')
            code.append(f'\t\tstd::memcpy(buffer.data() + offset, &len_{field_name}, sizeof(cct::UInt32));')
            code.append(f'\t\toffset += sizeof(cct::UInt32);')
            code.append(f'\t\tstd::memcpy(buffer.data() + offset, {field_name}.data(), {field_name}.size());')
            code.append(f'\t\toffset += {field_name}.size();')
        else:
            code.append(f'\t\t{cpp_type} temp_{field_name} = cct::ByteSwap({field_name});')
            code.append(f'\t\tstd::memcpy(buffer.data() + offset, &temp_{field_name}, sizeof({cpp_type}));')
            code.append(f'\t\toffset += sizeof({cpp_type});')
    code.append("\t\treturn buffer;")
    code.append("\t}")
    code.append("")
    code.append(f'\tstatic {class_name} deserialize(std::span<const cct::Byte> buffer) {{')
    code.append(f'\t\t{class_name} obj;')
    code.append("\t\tsize_t offset = 0;")
    for col in table["columns"]:
        cpp_type = type_mapping[col["type"]]["cpp"]
        field_name = snake_to_field(col["name"])
        if col["type"] == "str":
            code.append(f'\t\tcct::UInt32 len_{field_name};')
            code.append(f'\t\tstd::memcpy(&len_{field_name}, buffer.data() + offset, sizeof(cct::UInt32));')
            code.append(f'\t\tlen_{field_name} = cct::ByteSwap(len_{field_name});')
            code.append(f'\t\toffset += sizeof(cct::UInt32);')
            code.append(f'\t\tobj.{field_name}.assign(reinterpret_cast<const char*>(buffer.data() + offset), len_{field_name});')
            code.append(f'\t\toffset += len_{field_name};')
        else:
            code.append(f'\t\t{cpp_type} temp_{field_name};')
            code.append(f'\t\tstd::memcpy(&temp_{field_name}, buffer.data() + offset, sizeof({cpp_type}));')
            code.append(f'\t\tobj.{field_name} = cct::ByteSwap(temp_{field_name});')
            code.append(f'\t\toffset += sizeof({cpp_type});')
    code.append("\t\treturn obj;")
    code.append("\t}")
    code.append("};")
    return "\n".join(code)

def write_to_file(filename: str, content: str):
    output_dir = os.path.dirname(filename)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)

def main():
    args = sys.argv
    if len(args) != 4:
        print("Usage: python generate_bindings.py lang output_file json_file")
        return

    lang = args[1]
    output_file = args[2]
    json_file = args[3]
    if lang not in ["cpp", "rust"]:
        print("Invalid language")
        return

    with open(json_file, "r", encoding="utf-8") as f:
        json_data = json.load(f)
        if lang == "cpp":
            cpp_code = generate_cpp_file(json_data)
            write_to_file(output_file, cpp_code)
        elif lang == "rust":
            rust_code = generate_sql_file(json_data) + "\n\n" +  generate_rust_file(json_data)
            write_to_file(output_file, rust_code)

if __name__ == "__main__":
    main()
